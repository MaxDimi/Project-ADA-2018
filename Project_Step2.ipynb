{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing IRA tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import col, when, length\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data directory\n",
    "DATA_DIR = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting to know our main dataset\n",
    "\n",
    "## TODO: Should we keep track of which tweet is Iranian and which one is Russian?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_text_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(DATA_DIR+'*_troll_tweet_text.csv')\n",
    "tweets_stats_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(DATA_DIR+'*_troll_tweet_stats.csv')\n",
    "tweets_meta_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(DATA_DIR+'*_troll_tweet_metadata.csv')\n",
    "tweets_user_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(DATA_DIR+'*_troll_user.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10164244, 3)\n",
      "(10164244, 17)\n",
      "(10164244, 6)\n",
      "(4327, 11)\n"
     ]
    }
   ],
   "source": [
    "print((tweets_text_df.count(), len(tweets_text_df.columns)))\n",
    "print((tweets_stats_df.count(), len(tweets_stats_df.columns)))\n",
    "print((tweets_meta_df.count(), len(tweets_meta_df.columns)))\n",
    "print((tweets_user_df.count(), len(tweets_user_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweets_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10164244, 3)\n",
      "+------------------+--------------+--------------------+\n",
      "|           tweetid|tweet_language|          tweet_text|\n",
      "+------------------+--------------+--------------------+\n",
      "|877919995476496385|            ru|\"RT @ruopentwit: ...|\n",
      "|492388766930444288|            ru|Серебром отколоко...|\n",
      "|719455077589721089|            bg|@kpru С-300 в Ира...|\n",
      "|536179342423105537|            ru|Предлагаю судить ...|\n",
      "|841410788409630720|            bg|Предостережение а...|\n",
      "|834365760776630272|            ru|Двойная утопия, и...|\n",
      "|577490527299457024|            ru|RT @harkovnews: Н...|\n",
      "|596522755379560448|            ru|RT @NovostiNsk: «...|\n",
      "|567357519547207680|            en|As sun and cloud ...|\n",
      "|665533117369876480|            ru|RT @vesti_news: Ш...|\n",
      "+------------------+--------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print((tweets_text_df.count(), len(tweets_text_df.columns)))\n",
    "tweets_text_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unknown *tweet_language* can take both the value 'und', or null. We harmonize this column by setting all NaN to 'und'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_text_df = tweets_text_df.fillna('und',['tweet_language'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweets_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10164244, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('tweetid', 'string'),\n",
       " ('userid', 'string'),\n",
       " ('tweet_time', 'string'),\n",
       " ('in_reply_to_tweetid', 'string'),\n",
       " ('in_reply_to_userid', 'string'),\n",
       " ('quoted_tweet_tweetid', 'string'),\n",
       " ('is_retweet', 'string'),\n",
       " ('retweet_userid', 'string'),\n",
       " ('retweet_tweetid', 'string'),\n",
       " ('quote_count', 'string'),\n",
       " ('reply_count', 'string'),\n",
       " ('like_count', 'string'),\n",
       " ('retweet_count', 'string'),\n",
       " ('hashtags', 'string'),\n",
       " ('urls', 'string'),\n",
       " ('user_mentions', 'string'),\n",
       " ('poll_choices', 'string')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((tweets_stats_df.count(), len(tweets_stats_df.columns)))\n",
    "tweets_stats_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first convert the *tweet_time* into Datetime for ease of use, and we cast some columns into integers. We also create a static sql view of the main dataframe on which we can apply our SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_stats_df = tweets_stats_df.withColumn('tweet_time', to_timestamp(tweets_stats_df.tweet_time))\n",
    "tweets_stats_df = tweets_stats_df.withColumn('quote_count', tweets_stats_df.quote_count.cast('int'))\n",
    "tweets_stats_df = tweets_stats_df.withColumn('reply_count', tweets_stats_df.reply_count.cast('int'))\n",
    "tweets_stats_df = tweets_stats_df.withColumn('like_count', tweets_stats_df.like_count.cast('int'))\n",
    "tweets_stats_df = tweets_stats_df.withColumn('retweet_count', tweets_stats_df.retweet_count.cast('int'))\n",
    "tweets_stats_df.createOrReplaceTempView(\"tweets_stats_sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start splitting the data into smaller dataframes and remove the useless columns for each of those:\n",
    "* **retweets_df** contains all the posts that are retweets.\n",
    "* **replies_df** contains all the posts that are replies to other tweets.\n",
    "* **normal_tweets_df** contains all the other ('normal') posts.\n",
    "\n",
    "**NB:** some tweets have a value for *in_reply_to_userid* while their *in_reply_to_tweetid* is null (however the inverse never happens). Those are either replies to deleted tweets, or mentions of other users that were treated as replies. We decided to consider them as normal tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3565521, 9)\n"
     ]
    }
   ],
   "source": [
    "# RETWEETS\n",
    "retweets_df = spark.sql(\"SELECT * FROM tweets_stats_sql WHERE is_retweet=True\")\n",
    "\n",
    "# To understand how we selected the columns to remove, uncomment the next two lines\n",
    "#for col in retweets_df:\n",
    "#    retweets_df.select(col).distinct().show(10)\n",
    "\n",
    "retweets_df = retweets_df.drop('in_reply_to_tweetid', 'in_reply_to_userid', 'is_retweet', 'quote_count', 'reply_count', 'like_count', 'retweet_count', 'poll_choices')\n",
    "print((retweets_df.count(), len(retweets_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605558, 14)\n"
     ]
    }
   ],
   "source": [
    "# REPLIES\n",
    "replies_df = spark.sql(\"SELECT * FROM tweets_stats_sql WHERE is_retweet=False AND in_reply_to_tweetid IS NOT NULL\")\n",
    "replies_df = replies_df.drop('retweet_tweetid', 'retweet_userid', 'is_retweet')\n",
    "print((replies_df.count(), len(replies_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5993165, 13)\n"
     ]
    }
   ],
   "source": [
    "# NORMAL\n",
    "normal_tweets_df = spark.sql(\"SELECT * FROM tweets_stats_sql WHERE is_retweet=False AND in_reply_to_tweetid IS NULL\")\n",
    "normal_tweets_df = normal_tweets_df.drop('in_reply_to_tweetid', 'retweet_tweetid', 'retweet_userid', 'is_retweet')\n",
    "print((normal_tweets_df.count(), len(normal_tweets_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We verify that the number of rows correspond and that we did not duplicate or remove any by accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10164244 10164244\n"
     ]
    }
   ],
   "source": [
    "print(tweets_stats_df.count(), retweets_df.count()+normal_tweets_df.count()+replies_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweets_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10164244, 6)\n",
      "+------------------+--------------+---------------+--------+---------+------------------+\n",
      "|           tweetid|follower_count|following_count|latitude|longitude| tweet_client_name|\n",
      "+------------------+--------------+---------------+--------+---------+------------------+\n",
      "|849295393867399169|          4042|           1470|    null|     null|Twitter Web Client|\n",
      "|567280957913587713|           272|            390|    null|     null|          iziaslav|\n",
      "|493095247690612736|            89|            223|    null|     null|          vavilonX|\n",
      "|493892174069903360|            89|            223|    null|     null|          vavilonX|\n",
      "|512503798506721280|            89|            223|    null|     null|          vavilonX|\n",
      "|499624206246871041|            89|            223|    null|     null|          vavilonX|\n",
      "|491828568251707392|            89|            223|    null|     null|          vavilonX|\n",
      "|493768356810731520|            89|            223|    null|     null|          vavilonX|\n",
      "|502221368222814209|            89|            223|    null|     null|          vavilonX|\n",
      "|502380098495213568|            89|            223|    null|     null|          vavilonX|\n",
      "+------------------+--------------+---------------+--------+---------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print((tweets_meta_df.count(), len(tweets_meta_df.columns)))\n",
    "tweets_meta_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_meta_df.createOrReplaceTempView(\"tweets_meta_sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the number of rows with a non-null *latitude*/*longitude* combination is very small compared to the size of dataset (less than 0.05%). Furthermore, several of them are repeated. We thus consider it rather useless and prefer dropping it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10164244 4811 2958\n"
     ]
    }
   ],
   "source": [
    "temp = spark.sql(\"SELECT * FROM tweets_meta_sql WHERE latitude IS NOT NULL\")\n",
    "print(tweets_meta_df.count(), temp.count(), temp.select('latitude', 'longitude').distinct().count())\n",
    "\n",
    "tweets_meta_df = tweets_meta_df.drop('latitude', 'longitude')\n",
    "tweets_meta_df.createOrReplaceTempView(\"tweets_meta_sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main feature that we can use to split the data here is *tweet_client_name*. When we take a closer look to this column, we discover that there are more than 400 values registered. Many of them seem unidentifiable.\n",
    "\n",
    "However, we can see that a good amount of tweets are sent through official Twitter applications:\n",
    "* **Twitter Web Client** accounts for around one third of the tweets in the dataset.\n",
    "* **TweetDeck**, which allows to manage multiple accounts simultaneously, handles around 7% of the tweets.\n",
    "* **Twitter For Android** is also in the top 15 applications used for those tweets.\n",
    "\n",
    "Most of the other tweets are generated through automated social media managers, such as **twitterfeed** (which shut down in 2016), **dlvr.it**, or even **IFTTT**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n",
      "+-------------------+-------+\n",
      "|  tweet_client_name|  count|\n",
      "+-------------------+-------+\n",
      "| Twitter Web Client|3275944|\n",
      "|        twitterfeed|1472548|\n",
      "|          TweetDeck| 708585|\n",
      "|      newtwittersky| 393074|\n",
      "|          bronislav| 308516|\n",
      "|              IFTTT| 300152|\n",
      "|           iziaslav| 299963|\n",
      "|          rostislav| 289475|\n",
      "|        generationπ| 285503|\n",
      "|         Twibble.io| 268402|\n",
      "|    Ohwee Messanger| 240051|\n",
      "|Twitter for Android| 225275|\n",
      "|            dlvr.it| 224024|\n",
      "|NovaPress Publisher| 204583|\n",
      "|Приложение для тебя| 159588|\n",
      "+-------------------+-------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = spark.sql(\"SELECT tweet_client_name, COUNT(*) AS count FROM tweets_meta_sql GROUP BY tweet_client_name ORDER BY count DESC\")\n",
    "print(temp.count())\n",
    "temp.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "+--------------------+-------+\n",
      "|   tweet_client_name|  count|\n",
      "+--------------------+-------+\n",
      "|  Twitter Web Client|3275944|\n",
      "| Twitter for Android| 225275|\n",
      "|  Twitter for iPhone|  60141|\n",
      "|        Twitter Lite|  26199|\n",
      "|Twitter for Andro...|  22190|\n",
      "|Twitter for Websites|  14706|\n",
      "|    Twitter for iPad|   5572|\n",
      "|Twitter for  Android|   3642|\n",
      "|      Twitter Nation|    813|\n",
      "|Twitter for Nokia...|    442|\n",
      "| Twitter for Windows|    133|\n",
      "|Twitter for Black...|    126|\n",
      "|Twitter for Windo...|     87|\n",
      "|Twitter for Black...|     71|\n",
      "|Twitterrific for iOS|     21|\n",
      "|         Twitter Ads|     12|\n",
      "|Twitter Business ...|      2|\n",
      "|         Twitterfall|      1|\n",
      "|Unfollow Tools fo...|      1|\n",
      "|Twitter.com inc     |      1|\n",
      "+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = spark.sql(\"SELECT tweet_client_name, COUNT(*) AS count FROM tweets_meta_sql WHERE tweet_client_name LIKE '%Twitter%' GROUP BY tweet_client_name ORDER BY count DESC\")\n",
    "print(temp.count())\n",
    "temp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, seeing how messy this dataset is, and how few (small) columns it has, we decided to not split it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10164244, 4)\n"
     ]
    }
   ],
   "source": [
    "print((tweets_meta_df.count(), len(tweets_meta_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweets_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4327, 11)\n",
      "['userid', 'user_display_name', 'user_screen_name', 'user_reported_location', 'user_profile_description', 'user_profile_url', 'account_creation_date', 'account_language', 'follower_count', 'following_count', 'last_tweet_at']\n"
     ]
    }
   ],
   "source": [
    "print((tweets_user_df.count(), len(tweets_user_df.columns)))\n",
    "print(tweets_user_df.columns)\n",
    "#tweets_user_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first convert the dates and integers present in the dataframe. This also treats the wrong encodings in those columns (such as a language ('en') present in *last_tweet_at*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_user_df = tweets_user_df.withColumn('account_creation_date', to_timestamp(tweets_user_df.account_creation_date))\n",
    "tweets_user_df = tweets_user_df.withColumn('last_tweet_at', to_timestamp(tweets_user_df.last_tweet_at))\n",
    "tweets_user_df = tweets_user_df.withColumn('follower_count', tweets_user_df.follower_count.cast('int'))\n",
    "tweets_user_df = tweets_user_df.withColumn('following_count', tweets_user_df.following_count.cast('int'))\n",
    "tweets_user_df.createOrReplaceTempView(\"tweets_user_sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There also appear to be some wrong encodings in *account_language*. All languages are represented by a two letters code (except for *en-gb* and *zh-cn*, which correspond respectively to British English and Mainland Chinese). But a very small number of rows contain a date or a text as language.\n",
    "\n",
    "After looking further into that, we discovered that those accounts wrote tweets in many different languages. As it is impossible for us to determine which one is their preferred language, we decided to set those inconsistent values to *'und'*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with inconsistent account_language: 6\n",
      "+--------------------+--------------------+\n",
      "|              userid|    account_language|\n",
      "+--------------------+--------------------+\n",
      "|02b81295dbf8951d1...|          2016-01-13|\n",
      "|          1240007161|          2013-03-03|\n",
      "|8e77873eecf19db8d...|          2017-03-21|\n",
      "|943154a86aa64a498...| islami bilgilər ...|\n",
      "|bac526884ab0d54de...|          2017-03-02|\n",
      "|bc1f64b72afcf37d0...|          2017-02-04|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = spark.sql(\"SELECT userid, account_language FROM tweets_user_sql WHERE LENGTH(account_language)>5\")\n",
    "print(\"Number of rows with inconsistent account_language: \" + str(temp.count()))\n",
    "temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_text_df.createOrReplaceTempView(\"tweets_text_sql\")\n",
    "# temp = spark.sql(\"SELECT U.userid, account_language, tweet_language FROM tweets_user_sql U, tweets_stats_sql S, tweets_text_sql T WHERE LENGTH(account_language)>5 AND U.userid=S.userid AND S.tweetid=T.tweetid\")\n",
    "# temp.dropDuplicates(['userid', 'tweet_language']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_user_df = tweets_user_df.withColumn('account_language', when(length(col('account_language'))>5, 'und').otherwise(col('account_language')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_user_df.createOrReplaceTempView(\"tweets_user_sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with inconsistent account_language: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows with inconsistent account_language: \" + str(spark.sql(\"SELECT userid, account_language FROM tweets_user_sql WHERE LENGTH(account_language)>5\").count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split this dataframe into two:\n",
    "* **anonymized_user_df** contains all the users that are anonymized.\n",
    "* **exposed_user_df** contains all the other users.\n",
    "\n",
    "This allows us to drop two columns for the anonymized users, which are a majority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4327 4118 209\n"
     ]
    }
   ],
   "source": [
    "anonymized_user_df = spark.sql(\"SELECT * FROM tweets_user_sql WHERE userid=user_display_name\")\n",
    "exposed_user_df = spark.sql(\"SELECT * FROM tweets_user_sql WHERE NOT userid=user_display_name\")\n",
    "\n",
    "anonymized_user_df = anonymized_user_df.drop('user_display_name', 'user_screen_name')\n",
    "\n",
    "print(tweets_user_df.count(), anonymized_user_df.count(), exposed_user_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "We have generated 4 main dataframes from the data files: *tweets_text_df*, *tweets_stats_df*, *tweets_meta_df*, and *tweets_user_df*. We then cleaned the inconsistent values and split those dataframes into smaller ones when possible and useful. Our data is now organised as follows:\n",
    "\n",
    "* **tweets_text_df**: all the contents from the tweets, with an indication of their language.\n",
    "* **tweets_stats_df**: \n",
    "    * **retweets_df**: all the information about retweets.\n",
    "    * **replies_df**: all the information about replies.\n",
    "    * **normal_tweets_df**: all the information about the other tweets.\n",
    "* **tweets_meta_df**: all the meta information corresponding to each tweets (minus the latitude/longitude).\n",
    "* **tweets_user_df**:\n",
    "    * **anonymized_user_df**: all the information about anonymized users.\n",
    "    * **exposed_user_df**: all the information about users who are not anonymized.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
