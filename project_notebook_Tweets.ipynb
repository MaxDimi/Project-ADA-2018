{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project -- Analysing IRA tweets --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import to_timestamp, isnan\n",
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import col, when, length\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings # comment if you want to get the warnings from Searborn... ;) \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data directory\n",
    "DATA_DIR = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main parts in this current *Jupyter Notebook* :\n",
    "\n",
    "* 1) **GETTING TO KNOW OUR MAIN DATASETS**. We intend to understand what contain our datasets (features and their dtypes) and to clean them in order to be ready for interpretation. We also may want to split or create new sub-datasets if there are interesting opportunities to do so.\n",
    "\n",
    "\n",
    "* 2) **DESCRIPTIVE STATISTICS AND PROJECT FEASABILITY**. In this part of the notebook we want to give summary statistics about the datasets we will need the most for our project. Furthermore we will try to figure out whether or not our objectives of Milestone 1 are still feasible after the reading of our datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GETTING TO KNOW OUR MAIN DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking IRAN tweets into account or not \n",
    "include_iran = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets thanks to Spark CSV reader \n",
    "\n",
    "if include_iran:\n",
    "    \n",
    "    # combine both RUS and IRAN datasets\n",
    "    include_description = 'RUS & IRAN'\n",
    "    \n",
    "    tweets_text_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(DATA_DIR+'*_troll_tweet_text.csv')\n",
    "    tweets_stats_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(DATA_DIR+'*_troll_tweet_stats.csv')\n",
    "    tweets_meta_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(DATA_DIR+'*_troll_tweet_metadata.csv')\n",
    "    tweets_user_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(DATA_DIR+'*_troll_user.csv')\n",
    "\n",
    "else:\n",
    "    \n",
    "    # take only RUS datasets\n",
    "    include_description = 'RUS'\n",
    "    \n",
    "    tweets_text_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(DATA_DIR+'rus_troll_tweet_text.csv')\n",
    "    tweets_stats_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(DATA_DIR+'rus_troll_tweet_stats.csv')\n",
    "    tweets_meta_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(DATA_DIR+'rus_troll_tweet_metadata.csv')\n",
    "    tweets_user_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(DATA_DIR+'rus_troll_user.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sizes of the datasets : (RUS)\n",
      " --------------------------------------------------------\n",
      "size of troll_tweet_text : (9041308, 3)\n",
      "size of troll_tweet_stats : (9041308, 17)\n",
      "size of troll_tweet_metadata : (9041308, 6)\n",
      "size of troll_user : (3667, 11)\n"
     ]
    }
   ],
   "source": [
    "# look at the raw global datasets' sizes \n",
    "\n",
    "# n : number of observations\n",
    "n_text = tweets_text_df.count()\n",
    "n_stats = tweets_stats_df.count()\n",
    "n_metadata = tweets_meta_df.count()\n",
    "n_users = tweets_user_df.count()\n",
    "\n",
    "# d : dimensionality of the data \n",
    "d_text = len(tweets_text_df.columns)\n",
    "d_stats = len(tweets_stats_df.columns)\n",
    "d_metadata = len(tweets_meta_df.columns)\n",
    "d_users =  len(tweets_user_df.columns)\n",
    "\n",
    "# print the results \n",
    "print(' Sizes of the datasets : ('+include_description+')')\n",
    "print(' --------------------------------------------------------')\n",
    "print('size of troll_tweet_text : '+str((n_text,d_text)))\n",
    "print('size of troll_tweet_stats : '+str((n_stats,d_stats)))\n",
    "print('size of troll_tweet_metadata : '+str((n_metadata,d_metadata)))\n",
    "print('size of troll_user : '+str((n_users,d_users)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly more than 9M tweets are available from RUS datasets (10M when combining both RUS AND IRAN). If after the cleaning there remains such a large number of data points, it's most likely that our statistical tests will present some significance if there are really underlying correlations, differences ... etc. \n",
    "\n",
    "We can assume, since the number of records for each dataframe is the same and because of the '*a priori*' description of the data, that the rows are ordered in such a way that every tuple of index $i$ in '*troll_tweet_text*' corresponds to the observations at index $i$ for '*troll_tweet_stats*' and '*troll_tweet_metadata*'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweets_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9041308, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('tweetid', 'string'), ('tweet_language', 'string'), ('tweet_text', 'string')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what does tweets_text look like ? size, dtypes\n",
    "print((n_text,d_text))\n",
    "tweets_text_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+--------------------+\n",
      "|           tweetid|tweet_language|          tweet_text|\n",
      "+------------------+--------------+--------------------+\n",
      "|877919995476496385|            ru|\"RT @ruopentwit: ...|\n",
      "|492388766930444288|            ru|Серебром отколоко...|\n",
      "|719455077589721089|            bg|@kpru С-300 в Ира...|\n",
      "|536179342423105537|            ru|Предлагаю судить ...|\n",
      "|841410788409630720|            bg|Предостережение а...|\n",
      "|834365760776630272|            ru|Двойная утопия, и...|\n",
      "|577490527299457024|            ru|RT @harkovnews: Н...|\n",
      "|596522755379560448|            ru|RT @NovostiNsk: «...|\n",
      "|567357519547207680|            en|As sun and cloud ...|\n",
      "|665533117369876480|            ru|RT @vesti_news: Ш...|\n",
      "+------------------+--------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a quick view\n",
    "tweets_text_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Is there anything to clean at this stage (before playing/dealing with the data) ?*** \n",
    "\n",
    "Below are listed the interventions we needed to perform in order to clean the data :      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unknown *tweet_language* can take both the value 'und', or null. We harmonize this column by setting all NaN to 'und'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_text_df = tweets_text_df.fillna('und',['tweet_language'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweets_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9041308, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('tweetid', 'string'),\n",
       " ('userid', 'string'),\n",
       " ('tweet_time', 'string'),\n",
       " ('in_reply_to_tweetid', 'string'),\n",
       " ('in_reply_to_userid', 'string'),\n",
       " ('quoted_tweet_tweetid', 'string'),\n",
       " ('is_retweet', 'string'),\n",
       " ('retweet_userid', 'string'),\n",
       " ('retweet_tweetid', 'string'),\n",
       " ('quote_count', 'string'),\n",
       " ('reply_count', 'string'),\n",
       " ('like_count', 'string'),\n",
       " ('retweet_count', 'string'),\n",
       " ('hashtags', 'string'),\n",
       " ('urls', 'string'),\n",
       " ('user_mentions', 'string'),\n",
       " ('poll_choices', 'string')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what does tweets_stats look like ? size, dtypes\n",
    "print((n_stats,d_stats))\n",
    "tweets_stats_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a view is not adapted in the current context)\n",
    "# tweets_stats_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Is there anything to clean at this stage (before playing/dealing with the data) ?*** \n",
    "\n",
    "Below are listed the interventions we needed to perform in order to clean the data :      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first convert the *tweet_time* into Datetime for ease of use, and we cast some columns into integers. We also create a static sql view of the main dataframe on which we can apply our SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtypes transformations : \n",
    "tweets_stats_df = tweets_stats_df.withColumn('tweet_time', to_timestamp(tweets_stats_df.tweet_time))\n",
    "tweets_stats_df = tweets_stats_df.withColumn('quote_count', tweets_stats_df.quote_count.cast('int'))\n",
    "tweets_stats_df = tweets_stats_df.withColumn('reply_count', tweets_stats_df.reply_count.cast('int'))\n",
    "tweets_stats_df = tweets_stats_df.withColumn('like_count', tweets_stats_df.like_count.cast('int'))\n",
    "tweets_stats_df = tweets_stats_df.withColumn('retweet_count', tweets_stats_df.retweet_count.cast('int'))\n",
    "\n",
    "# create a temporary Spark SQL view\n",
    "tweets_stats_df.createOrReplaceTempView(\"tweets_stats_sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start splitting the data into smaller dataframes and remove the useless columns for each of those:\n",
    "* **retweets_df** contains all the posts that are retweets.\n",
    "* **replies_df** contains all the posts that are replies to other tweets.\n",
    "* **normal_tweets_df** contains all the other ('normal') posts.\n",
    "\n",
    "**NB:** some tweets have a value for *in_reply_to_userid* while their *in_reply_to_tweetid* is null (however the inverse never happens). Those are either replies to deleted tweets, or mentions of other users that were treated as replies. We decided to consider them as normal tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Size of the sub-dataset : (RUS)\n",
      " --------------------------------------------------------\n",
      "size of retweets : (3333184, 9)\n"
     ]
    }
   ],
   "source": [
    "# RETWEETS\n",
    "retweets_df = spark.sql(\"SELECT * FROM tweets_stats_sql WHERE is_retweet=True\")\n",
    "\n",
    "# to understand how we selected the columns to remove, uncomment the next two lines\n",
    "# => unique values for the whole column (either null, True , 0 ...)\n",
    "#for col in retweets_df:\n",
    "    #retweets_df.select(col).distinct().show(10)\n",
    "\n",
    "# drop certain features\n",
    "retweets_df = retweets_df.drop('in_reply_to_tweetid', 'in_reply_to_userid', 'is_retweet',\\\n",
    "                               'quote_count', 'reply_count', 'like_count', 'retweet_count',\\\n",
    "                               'poll_choices')\n",
    "\n",
    "# record the size of the created sub-dataset\n",
    "n_retweets = retweets_df.count()\n",
    "d_retweets = len(retweets_df.columns)\n",
    "\n",
    "# print the results\n",
    "print(' Size of the sub-dataset : ('+include_description+')')\n",
    "print(' --------------------------------------------------------')\n",
    "print('size of retweets : '+str((n_retweets,d_retweets)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Size of the sub-dataset : (RUS)\n",
      " --------------------------------------------------------\n",
      "size of replies : (266208, 14)\n"
     ]
    }
   ],
   "source": [
    "# REPLIES\n",
    "replies_df = spark.sql(\"SELECT * FROM tweets_stats_sql WHERE is_retweet=False AND in_reply_to_tweetid IS NOT NULL\")\n",
    "\n",
    "# to understand how we selected the columns to remove, uncomment the next two lines\n",
    "# => unique values for the whole column (either null, True , 0 ...)\n",
    "#for col in replies_df:\n",
    "    #replies_df.select(col).distinct().show(10)\n",
    "\n",
    "# record the size of the created sub-dataset\n",
    "replies_df = replies_df.drop('retweet_tweetid', 'retweet_userid', 'is_retweet')\n",
    "\n",
    "# record the size of the created sub-dataset\n",
    "n_replies = replies_df.count()\n",
    "d_replies = len(replies_df.columns)\n",
    "\n",
    "# print the results\n",
    "print(' Size of the sub-dataset : ('+include_description+')')\n",
    "print(' --------------------------------------------------------')\n",
    "print('size of replies : '+str((n_replies,d_replies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Size of the sub-dataset : (RUS)\n",
      " --------------------------------------------------------\n",
      "size of normal tweets : (5441916, 13)\n"
     ]
    }
   ],
   "source": [
    "# NORMAL\n",
    "normal_tweets_df = spark.sql(\"SELECT * FROM tweets_stats_sql WHERE is_retweet=False AND in_reply_to_tweetid IS NULL\")\n",
    "\n",
    "# to understand how we selected the columns to remove, uncomment the next two lines\n",
    "# => unique values for the whole column (either null, True , 0 ...)\n",
    "#for col in normal_tweets_df:\n",
    "    #normal_tweets_df.select(col).distinct().show(10)\n",
    "    \n",
    "# record the size of the created sub-dataset\n",
    "normal_tweets_df = normal_tweets_df.drop('in_reply_to_tweetid', 'retweet_tweetid', 'retweet_userid', 'is_retweet')\n",
    "\n",
    "# record the size of the created sub-dataset\n",
    "n_normal = normal_tweets_df.count()\n",
    "d_normal = len(normal_tweets_df.columns)\n",
    "\n",
    "# print the results\n",
    "print(' Size of the sub-dataset : ('+include_description+')')\n",
    "print(' --------------------------------------------------------')\n",
    "print('size of normal tweets : '+str((n_normal,d_normal)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We verify that the number of rows correspond and that we did not duplicate or remove any by accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9041308 vs. 9041308\n"
     ]
    }
   ],
   "source": [
    "print(str(n_stats)+' vs. '+str(n_retweets+n_normal+n_replies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweets_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9041308, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('tweetid', 'string'),\n",
       " ('follower_count', 'string'),\n",
       " ('following_count', 'string'),\n",
       " ('latitude', 'string'),\n",
       " ('longitude', 'string'),\n",
       " ('tweet_client_name', 'string')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what does tweets_stats look like ? size, dtypes\n",
    "print((n_metadata,d_metadata))\n",
    "tweets_meta_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+---------------+--------+---------+------------------+\n",
      "|           tweetid|follower_count|following_count|latitude|longitude| tweet_client_name|\n",
      "+------------------+--------------+---------------+--------+---------+------------------+\n",
      "|849295393867399169|          4042|           1470|    null|     null|Twitter Web Client|\n",
      "|567280957913587713|           272|            390|    null|     null|          iziaslav|\n",
      "|493095247690612736|            89|            223|    null|     null|          vavilonX|\n",
      "|493892174069903360|            89|            223|    null|     null|          vavilonX|\n",
      "|512503798506721280|            89|            223|    null|     null|          vavilonX|\n",
      "|499624206246871041|            89|            223|    null|     null|          vavilonX|\n",
      "|491828568251707392|            89|            223|    null|     null|          vavilonX|\n",
      "|493768356810731520|            89|            223|    null|     null|          vavilonX|\n",
      "|502221368222814209|            89|            223|    null|     null|          vavilonX|\n",
      "|502380098495213568|            89|            223|    null|     null|          vavilonX|\n",
      "+------------------+--------------+---------------+--------+---------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a quick view\n",
    "tweets_meta_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Is there anything to clean at this stage (before playing/dealing with the data) ?*** \n",
    "\n",
    "Below are listed the interventions we needed to perform in order to clean the data :      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as with the previous dataset, we cast some columns into integers and we also create a static sql view of the main dataframe on which we can apply our SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtypes transformations : \n",
    "tweets_meta_df = tweets_meta_df.withColumn('follower_count', tweets_meta_df.follower_count.cast('int'))\n",
    "tweets_meta_df = tweets_meta_df.withColumn('following_count', tweets_meta_df.following_count.cast('int'))\n",
    "\n",
    "# NOTE : we do not cast lattitude/longitude columns into integers since we intend to drop both \n",
    "# columns (see below why).\n",
    "\n",
    "# create a temporary Spark SQL view\n",
    "tweets_meta_df.createOrReplaceTempView(\"tweets_meta_sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the number of rows with a non-null *latitude*/*longitude* combination is very small compared to the size of dataset (less than 0.05%). Furthermore, several of them are repeated. We thus consider it rather useless and prefer dropping it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@answer : **REPEATED, is it really BAD ?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of observations for this data set 9041308\n",
      "number of non NULL lattitude records : 4779 and among them 2938 unique coordinates pairs\n"
     ]
    }
   ],
   "source": [
    "temp = spark.sql(\"SELECT * FROM tweets_meta_sql WHERE latitude IS NOT NULL\")\n",
    "print('total number of observations for this data set '+str(n_metadata))\n",
    "print('number of non NULL lattitude records : '+str(temp.count())+ ' and among them '+str(temp.select('latitude', 'longitude').distinct().count())+' unique coordinates pairs')\n",
    "\n",
    "# drop lattitude and longitude \n",
    "tweets_meta_df = tweets_meta_df.drop('latitude', 'longitude')\n",
    "      \n",
    "# override previous TempView\n",
    "tweets_meta_df.createOrReplaceTempView(\"tweets_meta_sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main feature that we can use to split the data here is *tweet_client_name*. When we take a closer look to this column, we discover that there are more than 400 values registered. Many of them seem unidentifiable.\n",
    "\n",
    "However, we can see that a good amount of tweets are sent through official Twitter applications:\n",
    "* **Twitter Web Client** accounts for around one third of the tweets in the dataset.\n",
    "* **TweetDeck**, which allows to manage multiple accounts simultaneously, handles around 7% of the tweets.\n",
    "* **Twitter For Android** is also in the top 15 applications used for those tweets.\n",
    "\n",
    "Most of the other tweets are generated through automated social media managers, such as **twitterfeed** (which had been shut down in 2016), **dlvr.it**, or even **IFTTT**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of twitter clients : 334\n",
      "+-------------------+-------+\n",
      "|  tweet_client_name|  count|\n",
      "+-------------------+-------+\n",
      "| Twitter Web Client|2576596|\n",
      "|        twitterfeed|1472547|\n",
      "|          TweetDeck| 612024|\n",
      "|      newtwittersky| 393074|\n",
      "|          bronislav| 308516|\n",
      "|           iziaslav| 299963|\n",
      "|              IFTTT| 291269|\n",
      "|          rostislav| 289475|\n",
      "|        generationπ| 285503|\n",
      "|         Twibble.io| 268402|\n",
      "|    Ohwee Messanger| 240051|\n",
      "|NovaPress Publisher| 204583|\n",
      "|Twitter for Android| 163227|\n",
      "|Приложение для тебя| 159588|\n",
      "|           vavilonX| 148744|\n",
      "+-------------------+-------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = spark.sql(\"SELECT tweet_client_name, COUNT(*) AS count FROM tweets_meta_sql GROUP BY tweet_client_name ORDER BY count DESC\")\n",
    "print('number of twitter clients : '+str(temp.count()))\n",
    "temp.show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look on Twitter clients of the kind : *Twitter ... for ....*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of such typical twitter clients : 18\n",
      "+--------------------+-------+\n",
      "|   tweet_client_name|  count|\n",
      "+--------------------+-------+\n",
      "|  Twitter Web Client|2576596|\n",
      "| Twitter for Android| 163227|\n",
      "|  Twitter for iPhone|  56168|\n",
      "|Twitter for Andro...|  22126|\n",
      "|    Twitter for iPad|   4432|\n",
      "|Twitter for  Android|   3642|\n",
      "|        Twitter Lite|   2891|\n",
      "|      Twitter Nation|    813|\n",
      "|Twitter for Websites|    762|\n",
      "|Twitter for Nokia...|    442|\n",
      "|Twitter for Black...|     92|\n",
      "| Twitter for Windows|     92|\n",
      "|Twitter for Black...|     71|\n",
      "|Twitterrific for iOS|     21|\n",
      "|Twitter for Windo...|      9|\n",
      "|         Twitter Ads|      6|\n",
      "|Twitter Business ...|      2|\n",
      "|Unfollow Tools fo...|      1|\n",
      "+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = spark.sql(\"SELECT tweet_client_name, COUNT(*) AS count FROM tweets_meta_sql WHERE tweet_client_name LIKE '%Twitter%' GROUP BY tweet_client_name ORDER BY count DESC\")\n",
    "print('number of such typical twitter clients : '+str(temp.count()))\n",
    "temp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, seeing how messy this dataset is, and how few columns it has, we decided to not split it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of troll_tweet_metadata : (9041308, 4)\n"
     ]
    }
   ],
   "source": [
    "# update the dimensionality of this dataset after the drop of columns\n",
    "d_metadata=  len(tweets_meta_df.columns)\n",
    "print('size of troll_tweet_metadata : '+str((n_metadata,d_metadata)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tweets_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3667, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('userid', 'string'),\n",
       " ('user_display_name', 'string'),\n",
       " ('user_screen_name', 'string'),\n",
       " ('user_reported_location', 'string'),\n",
       " ('user_profile_description', 'string'),\n",
       " ('user_profile_url', 'string'),\n",
       " ('account_creation_date', 'string'),\n",
       " ('account_language', 'string'),\n",
       " ('follower_count', 'string'),\n",
       " ('following_count', 'string'),\n",
       " ('last_tweet_at', 'string')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what does tweets_stats look like ? size, dtypes\n",
    "print((n_users,d_users))\n",
    "tweets_user_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Is there anything to clean at this stage (before playing/dealing with the data) ?*** \n",
    "\n",
    "Below are listed the interventions we needed to perform in order to clean the data :      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first convert the dates and integers present in the dataframe. This also treats the wrong encodings in those columns (such as a language ('en') present in *last_tweet_at*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtypes transformations : \n",
    "tweets_user_df = tweets_user_df.withColumn('account_creation_date', to_timestamp(tweets_user_df.account_creation_date))\n",
    "tweets_user_df = tweets_user_df.withColumn('last_tweet_at', to_timestamp(tweets_user_df.last_tweet_at))\n",
    "tweets_user_df = tweets_user_df.withColumn('follower_count', tweets_user_df.follower_count.cast('int'))\n",
    "tweets_user_df = tweets_user_df.withColumn('following_count', tweets_user_df.following_count.cast('int'))\n",
    "\n",
    "# create a temporary Spark SQL view\n",
    "tweets_user_df.createOrReplaceTempView(\"tweets_user_sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There also appear to be some wrong encodings in *account_language*. All languages are represented by a two letters code (except for *en-gb* and *zh-cn*, which correspond respectively to British English and Mainland Chinese). But a very small number of rows contain a date or a text as language.\n",
    "\n",
    "After looking further into that, we discovered that those accounts wrote tweets in many different languages. As it is impossible for us to determine which one is their preferred language, we decided to set those inconsistent values to *'und'*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows with inconsistent account_language: 3\n",
      "+--------------------+----------------+\n",
      "|              userid|account_language|\n",
      "+--------------------+----------------+\n",
      "|02b81295dbf8951d1...|      2016-01-13|\n",
      "|          1240007161|      2013-03-03|\n",
      "|8e77873eecf19db8d...|      2017-03-21|\n",
      "+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = spark.sql(\"SELECT userid, account_language FROM tweets_user_sql WHERE LENGTH(account_language)>5\")\n",
    "print(\"number of rows with inconsistent account_language: \" + str(temp.count()))\n",
    "temp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the transformations required by the last comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter on the account_language feature\n",
    "tweets_user_df = tweets_user_df.withColumn('account_language', when(length(col('account_language'))>5, 'und').otherwise(col('account_language')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temporary Spark SQL view\n",
    "tweets_user_df.createOrReplaceTempView(\"tweets_user_sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that there are no more 'inconsistent' rows w.r.t our standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows with inconsistent account_language: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"number of rows with inconsistent account_language: \" + str(spark.sql(\"SELECT userid, account_language FROM tweets_user_sql WHERE LENGTH(account_language)>5\").count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split this dataframe into two:\n",
    "* **anonymized_user_df** contains all the users that are anonymized.\n",
    "* **exposed_user_df** contains all the other users.\n",
    "\n",
    "This allows us to drop two columns for the anonymized users (users that have a *userid* that's the same as their *user_display_name* and *user_screen_name* : [Google APIs : twitter election integrity](https://storage.googleapis.com/twitter-election-integrity/hashed/Twitter_Elections_Integrity_Datasets_hashed_README.txt)) , which are a majority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of records from dataset user : 3667\n",
      "wherein there are 3500 anonymized accounts and 167 exposed accounts\n"
     ]
    }
   ],
   "source": [
    "anonymized_user_df = spark.sql(\"SELECT * FROM tweets_user_sql WHERE userid=user_display_name\")\n",
    "exposed_user_df = spark.sql(\"SELECT * FROM tweets_user_sql WHERE NOT userid=user_display_name\")\n",
    "\n",
    "# drop useless columns \n",
    "anonymized_user_df = anonymized_user_df.drop('user_display_name', 'user_screen_name')\n",
    "\n",
    "# print results + check that there are only two outcomes possible for userid = user_display_name\n",
    "print('number of records from dataset user : '+str(n_users))\n",
    "print('wherein there are '+str(anonymized_user_df.count())+' anonymized accounts and '+\\\n",
    "      str(exposed_user_df.count())+' exposed accounts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "We have generated 4 main dataframes from the data files: *tweets_text_df*, *tweets_stats_df*, *tweets_meta_df*, and *tweets_user_df*. We then cleaned the inconsistent values and split those dataframes into smaller ones when possible and useful. Our data is now organised as follows:\n",
    "\n",
    "* **tweets_text_df**: all the contents from the tweets, with an indication of their language.\n",
    "* **tweets_stats_df**: \n",
    "    * **retweets_df**: all the information about retweets.\n",
    "    * **replies_df**: all the information about replies.\n",
    "    * **normal_tweets_df**: all the information about the other tweets.\n",
    "* **tweets_meta_df**: all the meta information corresponding to each tweets (minus the latitude/longitude).\n",
    "* **tweets_user_df**:\n",
    "    * **anonymized_user_df**: all the information about anonymized users.\n",
    "    * **exposed_user_df**: all the information about users who are not anonymized.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before digging into some statistics we would like to underline the fact we can handle the data in its current size with the use of Spark. Previous requests did not take that much time with Spark SQL and the fact that our dataset is well partionned among several sub-datasets (data chunks) of interest will prevent us to query on too large files ! If we request very intensive computations on the data that embed many and many accesses to these chunks we will either make use of *Parquet* files or we will ***persist()*** Spark dataframes to keep them on top of the memory.\n",
    "We can tell we won't need to use ADA's cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  DESCRIPTIVE STATISTICS OF OUR DATASETS AND PROJECT FEASABILITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a short reminder, the questions we would like to address with respect to the milestone 1 were  : \n",
    "* 1) Is there a relation between the candidates popularities and the activities of the trolls?\n",
    "* 2) Did the trolls influence the major events of the campaign? Is it the other way around? \n",
    "* 3) Which subjects are discussed by the trolls, and which semantics do they use?\n",
    "* 4) Which media do they tend to talk about and link in their posts?\n",
    "* 5) Do they tend to show direct support or hatred for specific people?\n",
    "* 6) Did the strategy of the trolls change over time?\n",
    "    \n",
    "-------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first focus on the descriptive statistics of sub-datasets of **tweets_stats_df**. This will help us to assess the feasability of the questions 1) and 2) together with extra informations provided by websites (as we mentionned in our first *README* : [cesrusc/election](https://cesrusc.org/election/) , [fivethirtyeight/trump-approval-ratings](uhttps://projects.fivethirtyeight.com/trump-approval-ratings/?ex_cid=rrpromo) , [realclearpolitics/polls](https://www.realclearpolitics.com/epolls/latest_polls/president/#) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5441916, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('tweetid', 'string'),\n",
       " ('userid', 'string'),\n",
       " ('tweet_time', 'timestamp'),\n",
       " ('in_reply_to_userid', 'string'),\n",
       " ('quoted_tweet_tweetid', 'string'),\n",
       " ('quote_count', 'int'),\n",
       " ('reply_count', 'int'),\n",
       " ('like_count', 'int'),\n",
       " ('retweet_count', 'int'),\n",
       " ('hashtags', 'string'),\n",
       " ('urls', 'string'),\n",
       " ('user_mentions', 'string'),\n",
       " ('poll_choices', 'string')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display columns and their dtypes of normal tweets \n",
    "print((n_normal,d_normal))\n",
    "normal_tweets_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pre-suppose troll *normal_tweets* that have been collected by  [about_twitter/elections-integrity](https://about.twitter.com/en_us/values/elections-integrity.html#data) are messages advocating, insidiously or not, a preferential political position. At this stage we don't analyze yet the content of these tweets (pure trolls, fake news, researchs ... etc). Note that retweets and replies may have some influence as well on the population opinion. \n",
    "\n",
    "We will investigate this later, let's first show the distribution over time of the number of such *normal_tweets* that may convey the core of the inferences russian trolls wanted to apply on **america's twittosphere**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temporary Spark SQL view of normal_tweets_df\n",
    "normal_tweets_df.createOrReplaceTempView(\"normal_tweets_sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>2009</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27</td>\n",
       "      <td>2009</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>118</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>836</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1686</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2387</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  year  month\n",
       "0     20  2009      5\n",
       "1      6  2009      6\n",
       "2      8  2009      7\n",
       "3     14  2009      9\n",
       "4      6  2009     10\n",
       "5     27  2009     11\n",
       "6    118  2009     12\n",
       "7    836  2010      1\n",
       "8   1686  2010      2\n",
       "9   2387  2010      3"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert time_stamps into handy integers\n",
    "normal_dates_query = \"\"\"SELECT COUNT(tweetid) AS count, YEAR(tweet_time) AS year, MONTH(tweet_time) AS month\n",
    "                        FROM normal_tweets_sql\n",
    "                        GROUP BY YEAR(tweet_time),MONTH(tweet_time)\n",
    "                        ORDER BY YEAR(tweet_time) ASC, MONTH(tweet_time) ASC\n",
    "                     \"\"\"\n",
    "normal_dates_df = spark.sql(normal_dates_query)\n",
    "\n",
    "# store as a Panda dataframe (very small, absolutely no problem with the memory)\n",
    "normal_dates_pd = normal_dates_df.toPandas()\n",
    "\n",
    "# retrieve total number of months for which potential troll tweets have been detected\n",
    "n_months = normal_dates_pd.shape[0]\n",
    "\n",
    "# retrieve (only) the first month and first year\n",
    "date_ref = normal_dates_pd.iloc[0][1:]\n",
    "\n",
    "# print \n",
    "normal_dates_pd.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already observe that for some months the database doesn't contain any '*normal tweet*' !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the number of months that separate two dates (YEAR,MONTH)\n",
    "def months_space(tuple_now,tuple_start):\n",
    "    '''\n",
    "    INPUT\n",
    "    -----\n",
    "    tuple_now : tuple with the date (year,month) (int,int) to be tester\n",
    "    tuple_start : tuple with the reference date (year,month) (int,int) \n",
    "    \n",
    "    OUTPUT\n",
    "    ------\n",
    "    number of months 'elapsed' for instance, months_space((2013,1),(2012,3)) = 10 \n",
    "                                             months_space((2015,4),(2015,3)) = 1\n",
    "    '''\n",
    "    # retrieve years and months\n",
    "    year_now = tuple_now[0]\n",
    "    month_now = tuple_now[1]\n",
    "    year_start = tuple_start[0]\n",
    "    month_start = tuple_start[1]\n",
    "    \n",
    "    # return the number of months separating the two dates\n",
    "    return 12*(year_now-year_start) + (month_now-month_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For plotting purposes, let's add another column to the Pandas dataframe which gives the spacing (in terms of number of months) between the months where troll tweets were collected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dates_pd['months spacing'] = normal_dates_pd.apply(lambda x: 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>months spacing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>2009</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  year  month  months spacing\n",
       "0     20  2009      5             NaN\n",
       "1      6  2009      6             NaN\n",
       "2      8  2009      7             NaN\n",
       "3     14  2009      9             NaN\n",
       "4      6  2009     10             NaN"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_dates_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temporary Spark SQL view in order to select only the normal tweets\n",
    "# whose dates correspond the US presidential campaign\n",
    "normal_dates_df.createOrReplaceTempView(\"normal_dates_sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first normal tweet date (unix_time stamp) : 1241877540\n",
      "first normal tweet date (human readable) : 2009-05-09 13:59:00\n"
     ]
    }
   ],
   "source": [
    "# recover the date of the first troll normal_tweet identified\n",
    "start_normal_date_query = \"\"\"SELECT MIN(UNIX_TIMESTAMP(tweet_time)) FROM normal_tweets_sql\"\"\"\n",
    "\n",
    "start_normal_date = spark.sql(start_normal_date_query)\n",
    "start_normal_date = start_normal_date.head()[0] # access the value of the query \n",
    "\n",
    "print('first normal tweet date (unix_time stamp) : ' + str(start_normal_date))\n",
    "print('first normal tweet date (human readable) : '+str(pd.to_datetime(start_normal_date,unit='s')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That corresponds to a tweet back in 2009 (9th of may). As the presidential campaign didn't really begin so early we will certainly introduce a threshold of validity based on the date of apparition for date-based studies/researchs. \n",
    "\n",
    "The reason why we observe such timestamps could be :\n",
    "\n",
    "* weakness of the filter for troll data collection (false positive troll tweets)\n",
    "* tweak (did hackers manage to mislead data collectors by faking the date of their tweets?)\n",
    "* just another bug while recording the informations about the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot purposes (whole data without truncating and\n",
    "# without keeping only observations during the presidential campaign)\n",
    "sns.barplot(x = \"months elapsed\", y=\"count\", data=normal_dates_pd,\n",
    "                   color=\"blue\", saturation=.5)\n",
    "plt.title('')\n",
    "plt.xlabel('TimeResponse (sec) (log scale)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid()\n",
    "plt.legend(['histogram'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
